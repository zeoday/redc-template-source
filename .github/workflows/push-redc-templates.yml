name: Build and Deploy (Strict Versioning)

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:
    inputs:
      force_rebuild:
        description: 'Force rebuild all templates'
        required: false
        default: false
        type: boolean

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      # 1. æ‹‰å–æºç 
      - name: Checkout Source
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      # 2. æ‹‰å–æ—§æ„å»º (å¿…é¡»æ­¥éª¤ï¼šç”¨äºè·å–æ—§çš„ index.json å’Œ zip æ–‡ä»¶)
      - name: Checkout Previous Build (Safe)
        run: |
          echo "ğŸ” Checking for existing gh-pages branch..."
          if git ls-remote --exit-code --heads origin gh-pages; then
            echo "âœ… Branch found. Cloning cache..."
            git clone --depth=1 --branch=gh-pages https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git previous_build
          else
            echo "âš ï¸ Branch 'gh-pages' not found. Will build everything from scratch."
            mkdir -p previous_build
          fi

      # 3. æ™ºèƒ½æ„å»ºè„šæœ¬
      - name: Build with Python
        env:
          REPO_OWNER: ${{ github.repository_owner }}
          REPO_NAME: ${{ github.event.repository.name }}
          FORCE_REBUILD: ${{ inputs.force_rebuild }}
        run: |
          mkdir -p public/templates
          [ -f index.html ] && cp index.html public/index.html

          python3 -c "
          import os
          import json
          import shutil
          import hashlib
          import datetime

          # --- é…ç½® ---
          repo_owner = os.environ.get('REPO_OWNER')
          repo_name = os.environ.get('REPO_NAME')
          force_rebuild = os.environ.get('FORCE_REBUILD') == 'true'
          
          base_url = f'https://{repo_owner}.github.io/{repo_name}'
          output_dir = 'public'
          templates_dir = os.path.join(output_dir, 'templates')
          
          # ç¼“å­˜è·¯å¾„
          prev_build_dir = 'previous_build'
          prev_index_path = os.path.join(prev_build_dir, 'index.json')
          
          if not os.path.exists(templates_dir): os.makedirs(templates_dir)

          # --- 1. åŠ è½½æ—§ç‰ˆæœ¬ä¿¡æ¯ ---
          old_map = {}
          if os.path.exists(prev_index_path) and not force_rebuild:
              try:
                  with open(prev_index_path, 'r', encoding='utf-8') as f:
                      data = json.load(f)
                      for t in data.get('templates', []):
                          old_map[t['id']] = t
                  print(f'ğŸ“¦ Loaded history for {len(old_map)} templates.')
              except Exception as e:
                  print(f'âš ï¸ Failed to load previous index: {e}')

          # --- 2. éå†ä¸å¤„ç† ---
          new_templates = []
          repo_root = '.'
          exclude = {'.git', '.github', 'public', 'previous_build', 'README.md', '.gitignore', 'index.html'}

          for provider in sorted(os.listdir(repo_root)):
              provider_path = os.path.join(repo_root, provider)
              if not os.path.isdir(provider_path) or provider in exclude: continue

              for template in sorted(os.listdir(provider_path)):
                  template_path = os.path.join(provider_path, template)
                  if not os.path.isdir(template_path): continue

                  template_id = f'{provider}/{template}'
                  zip_name = f'{provider}_{template}.zip'
                  zip_output_path = os.path.join(templates_dir, zip_name)

                  # === è¯»å–å½“å‰ case.json ä¸­çš„ç‰ˆæœ¬ ===
                  meta_name = template
                  meta_user = 'Unknown'
                  meta_desc = 'No description.'
                  current_version = '0.0.1' # é»˜è®¤ç‰ˆæœ¬
                  
                  case_path = os.path.join(template_path, 'case.json')
                  try:
                      if os.path.exists(case_path):
                          with open(case_path, 'r', encoding='utf-8') as cf:
                              c = json.load(cf)
                              meta_name = c.get('name', template)
                              meta_user = c.get('user', 'Unknown')
                              meta_desc = c.get('DESCRIPTION', 'No description.')
                              current_version = c.get('version', '0.0.1')
                  except Exception as e:
                      print(f'âš ï¸ Error reading case.json for {template_id}: {e}')

                  # === æ ¸å¿ƒé€»è¾‘ï¼šç‰ˆæœ¬å¯¹æ¯” ===
                  should_rebuild = False
                  reason = 'Unknown'
                  
                  # è·å–æ—§ç‰ˆæœ¬ä¿¡æ¯
                  old_data = old_map.get(template_id)
                  prev_zip_path = os.path.join(prev_build_dir, 'templates', zip_name)
                  
                  if force_rebuild:
                      should_rebuild = True; reason = 'Forced'
                  elif not old_data:
                      should_rebuild = True; reason = 'New Template'
                  elif not os.path.exists(prev_zip_path):
                      should_rebuild = True; reason = 'Missing Artifact'
                  elif old_data.get('version') != current_version:
                      # å…³é”®åˆ¤æ–­ï¼šåªæœ‰ç‰ˆæœ¬å·ä¸ä¸€è‡´æ‰é‡å»º
                      should_rebuild = True
                      reason = f'Version Upgrade ({old_data.get("version")} -> {current_version})'
                  else:
                      reason = 'Version Match'

                  # === æ‰§è¡ŒåŠ¨ä½œ ===
                  final_hash = ''
                  
                  if should_rebuild:
                      print(f'ğŸ”¨ Building: {template_id} [{reason}]')
                      # æ‰“åŒ…
                      shutil.make_archive(zip_output_path.replace('.zip', ''), 'zip', root_dir=template_path)
                      
                      # è®¡ç®— Hash
                      h = hashlib.sha256()
                      with open(zip_output_path, 'rb') as f:
                          for chunk in iter(lambda: f.read(4096), b''): h.update(chunk)
                      final_hash = h.hexdigest()
                  else:
                      print(f'â© Skipping: {template_id} [{reason}]')
                      # ç›´æ¥å¤åˆ¶æ—§æ–‡ä»¶
                      shutil.copy2(prev_zip_path, zip_output_path)
                      # å¤ç”¨æ—§ Hash
                      final_hash = old_data['sha256']

                  # æ·»åŠ åˆ°åˆ—è¡¨
                  new_templates.append({
                      'id': template_id,
                      'provider': provider,
                      'slug': template,
                      'url': f'{base_url}/templates/{zip_name}',
                      'version': current_version,
                      'sha256': final_hash,
                      'updated_at': datetime.datetime.utcnow().isoformat() + 'Z',
                      'metadata': {
                          'name': meta_name,
                          'author': meta_user,
                          'description': meta_desc
                      }
                  })

          # --- ä¿å­˜ Index ---
          manifest = {
              'updated_at': datetime.datetime.utcnow().isoformat() + 'Z',
              'repo_name': repo_name,
              'templates': new_templates
          }
          
          with open(os.path.join(output_dir, 'index.json'), 'w', encoding='utf-8') as f:
              json.dump(manifest, f, indent=2, ensure_ascii=False)
          
          print(f'âœ¨ Build Complete. Total: {len(new_templates)}')
          "

      # 4. éƒ¨ç½² (å¿…é¡»ä½¿ç”¨ peaceiris/actions-gh-pages ä»¥ç»´æŒåˆ†æ”¯å†å²)
      - name: Deploy to gh-pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./public
          publish_branch: gh-pages
          commit_message: "Deploy: ${{ github.event.head_commit.message }}"
